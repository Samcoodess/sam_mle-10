{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "24d097db",
      "metadata": {
        "id": "24d097db"
      },
      "source": [
        "<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\"\n",
        "     width=\"200px\"\n",
        "     height=\"auto\"/>\n",
        "</p>\n",
        "\n",
        "# <h1 align=\"center\" id=\"heading\">Sentiment Analysis of Twitter Data</h1>\n",
        "\n",
        "<hr>\n",
        "\n",
        "\n",
        "### ‚òëÔ∏è Objectives\n",
        "At the end of this session, you will be able to:\n",
        "- [ ] Understand how to find and run pre-trained models\n",
        "- [ ] Evaluate results from pre-trained models\n",
        "- [ ] Run a pre-trained model using real twitter data\n",
        "\n",
        "\n",
        "### üî® Pre-Assignment\n",
        "\n",
        "Create a new Conda environment for sentiment anaylsis (sa)\n",
        "\n",
        "```bash\n",
        "  conda create -n sa python=3.8 jupyter -y\n",
        "```\n",
        "\n",
        "Activate your new environment\n",
        "```bash\n",
        "  conda activate sa\n",
        "```\n",
        "\n",
        "Open the jupyter-notebook\n",
        "```bash\n",
        "  jupyter-notebook\n",
        "```\n",
        "\n",
        "Navigate through the repo in the notebook to find `imports.ipynb` for this week and open it.\n",
        "\n",
        "Run all of the cells in the notebook.\n",
        "\n",
        "\n",
        "### Background\n",
        "Please review the weekly narrative [here](https://www.notion.so/Week-2-Data-Centric-AI-the-AI-Product-Lifecycle-72a84c1517b44fcbb3e6bd11d47477dc#2b73937612bb46559f5b91dc2bf55e7d)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3934e6e",
      "metadata": {
        "id": "b3934e6e"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6291d214",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5e8491e0edfc4ac5aca23cb61b22540a",
            "b768ffabf90f41c2afba6aed162bbf0a",
            "a4e1424640d84174a354de798b2ac519",
            "958c99a818e14bcbbb6b7473fbb188bc",
            "82e4ba54fb34437c8e39ba1614524470",
            "febbfa899e084f1db406fbd448178e54"
          ]
        },
        "id": "6291d214",
        "outputId": "f5c4db80-6449-4bab-898c-192ffaebadfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.8 MB 99 kB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting torch\n",
            "  Downloading torch-1.13.0-cp39-cp39-manylinux1_x86_64.whl (890.2 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 890.2 MB 800 bytes/s  0:00:012  |‚ñé                               | 8.0 MB 1.2 MB/s eta 0:12:15     |‚ñç                               | 10.1 MB 1.2 MB/s eta 0:12:13     |‚ñà‚ñà‚ñà‚ñä                            | 104.4 MB 4.2 MB/s eta 0:03:07     |‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 135.0 MB 162 kB/s eta 1:17:28     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 146.6 MB 5.7 MB/s eta 0:02:12     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 154.2 MB 5.4 MB/s eta 0:02:16     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 166.1 MB 6.2 MB/s eta 0:01:58     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 188.4 MB 5.0 MB/s eta 0:02:22     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 200.8 MB 4.2 MB/s eta 0:02:44     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 246.6 MB 5.2 MB/s eta 0:02:04     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 254.8 MB 6.9 MB/s eta 0:01:33     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 256.8 MB 6.9 MB/s eta 0:01:33     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 437.4 MB 3.8 MB/s eta 0:01:59     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 480.2 MB 4.6 MB/s eta 0:01:30     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 555.2 MB 4.4 MB/s eta 0:01:17     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 599.4 MB 3.1 MB/s eta 0:01:36     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 600.5 MB 4.7 MB/s eta 0:01:02     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 664.8 MB 5.7 MB/s eta 0:00:40     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 779.7 MB 1.0 MB/s eta 0:01:50     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 794.8 MB 7.0 MB/s eta 0:00:14     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 796.5 MB 7.0 MB/s eta 0:00:14     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 797.5 MB 715 kB/s eta 0:02:10ÔøΩ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 825.6 MB 84 kB/s eta 0:12:43     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 872.2 MB 209 kB/s eta 0:01:26     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 874.4 MB 209 kB/s eta 0:01:16\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/samcodess/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 182 kB 995 kB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /home/samcodess/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
            "Requirement already satisfied: requests in /home/samcodess/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
            "Requirement already satisfied: filelock in /home/samcodess/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/samcodess/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.6 MB 186 kB/s eta 0:00:01     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2.5 MB 5.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/samcodess/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/samcodess/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 317.1 MB 1.5 kB/s eta 0:00:01    |‚ñà‚ñà‚ñà‚ñé                            | 33.0 MB 5.0 MB/s eta 0:00:57                    | 50.0 MB 991 kB/s eta 0:04:30     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 51.7 MB 991 kB/s eta 0:04:28     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 77.8 MB 1.5 MB/s eta 0:02:38     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 160.3 MB 3.7 MB/s eta 0:00:43     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 173.6 MB 6.6 MB/s eta 0:00:22     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 179.7 MB 5.6 MB/s eta 0:00:25     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 181.0 MB 5.6 MB/s eta 0:00:25     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 192.8 MB 6.3 MB/s eta 0:00:20     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 215.7 MB 6.1 MB/s eta 0:00:17     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 219.5 MB 7.3 MB/s eta 0:00:14     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 220.1 MB 7.3 MB/s eta 0:00:14     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 224.2 MB 4.5 MB/s eta 0:00:21     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 276.1 MB 4.3 MB/s eta 0:00:10\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21.0 MB 5.5 MB/s eta 0:00:01    |‚ñà‚ñã                              | 1.0 MB 3.1 MB/s eta 0:00:07    |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 7.7 MB 609 kB/s eta 0:00:22ÔøΩ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 16.1 MB 1.2 MB/s eta 0:00:05\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557.1 MB 1.2 MB/s eta 0:00:010    |‚ñà‚ñà‚ñà                             | 52.2 MB 5.0 MB/s eta 0:01:41     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 93.3 MB 5.5 MB/s eta 0:01:26     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 131.2 MB 2.7 MB/s eta 0:02:40     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 163.1 MB 4.1 MB/s eta 0:01:37     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 167.6 MB 5.1 MB/s eta 0:01:16     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 202.9 MB 7.4 MB/s eta 0:00:49     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 228.1 MB 5.6 MB/s eta 0:01:00     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 232.8 MB 4.9 MB/s eta 0:01:07     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 243.2 MB 4.3 MB/s eta 0:01:14     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 244.4 MB 4.3 MB/s eta 0:01:13‚ñà‚ñà‚ñà‚ñè                 | 246.5 MB 4.3 MB/s eta 0:01:13     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 247.1 MB 4.3 MB/s eta 0:01:13  | 283.3 MB 6.1 MB/s eta 0:00:45ÔøΩÔøΩ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 283.5 MB 6.1 MB/s eta 0:00:45ÔøΩÔøΩ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 298.5 MB 7.9 MB/s eta 0:00:33     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 323.0 MB 22 kB/s eta 2:51:51     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 328.5 MB 22 kB/s eta 2:47:48   | 338.4 MB 4.8 MB/s eta 0:00:46     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 361.2 MB 5.8 MB/s eta 0:00:34     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 363.5 MB 5.8 MB/s eta 0:00:34ÔøΩÔøΩ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 379.2 MB 6.7 MB/s eta 0:00:27‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 407.6 MB 6.2 MB/s eta 0:00:25  |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 407.8 MB 6.2 MB/s eta 0:00:25‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 408.8 MB 6.2 MB/s eta 0:00:24kB/s eta 1:01:10     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 470.4 MB 8.4 MB/s eta 0:00:11     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 503.0 MB 5.4 MB/s eta 0:00:11ÔøΩÔøΩ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 515.7 MB 3.6 MB/s eta 0:00:12    |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 516.4 MB 3.6 MB/s eta 0:00:12‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 516.5 MB 3.6 MB/s eta 0:00:12    |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 521.2 MB 2.9 MB/s eta 0:00:13‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 521.3 MB 2.9 MB/s eta 0:00:13ÔøΩ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 521.5 MB 2.9 MB/s eta 0:00:13ÔøΩÔøΩ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 523.3 MB 74 kB/s eta 0:07:389 MB 6.9 MB/s eta 0:00:03     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 544.2 MB 6.7 MB/s eta 0:00:02     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 553.1 MB 5.7 MB/s eta 0:00:01‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 553.5 MB 5.7 MB/s eta 0:00:01     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557.1 MB 351 bytes/s \n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 849 kB 4.9 MB/s eta 0:00:01          | 245 kB 4.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /home/samcodess/anaconda3/lib/python3.9/site-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: wheel in /home/samcodess/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.0)\n",
            "Requirement already satisfied: setuptools in /home/samcodess/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (58.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /home/samcodess/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/samcodess/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/samcodess/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/samcodess/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/samcodess/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
            "Installing collected packages: nvidia-cublas-cu11, tokenizers, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, huggingface-hub, transformers, torch\n",
            "Successfully installed huggingface-hub-0.11.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 tokenizers-0.13.2 torch-1.13.0 transformers-4.25.1\n",
            "Requirement already satisfied: emoji==0.6.0 in /home/samcodess/anaconda3/lib/python3.9/site-packages (0.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-02 12:45:04.556088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-02 12:45:13.337750: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-12-02 12:45:13.337781: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2022-12-02 12:45:14.625797: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-12-02 12:45:46.585937: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2022-12-02 12:45:46.586290: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2022-12-02 12:45:46.586308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e8491e0edfc4ac5aca23cb61b22540a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/540M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b768ffabf90f41c2afba6aed162bbf0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/295 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4e1424640d84174a354de798b2ac519",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/843k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "958c99a818e14bcbbb6b7473fbb188bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82e4ba54fb34437c8e39ba1614524470",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "febbfa899e084f1db406fbd448178e54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install transformers torch\n",
        "!pip install emoji==0.6.0\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "pinstall = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a5ab14",
      "metadata": {
        "id": "d1a5ab14"
      },
      "source": [
        "## üöÄ Let's Get Started"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bea542cb",
      "metadata": {
        "id": "bea542cb"
      },
      "source": [
        "Let's first start with our imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f67dcb2b",
      "metadata": {
        "scrolled": true,
        "id": "f67dcb2b"
      },
      "outputs": [],
      "source": [
        "import csv # Allows us to read and write csv files\n",
        "from pprint import pprint # Make our print functions easier to read\n",
        "\n",
        "from transformers import pipeline # Hugging face pipeline to load online models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62d4028f",
      "metadata": {
        "id": "62d4028f"
      },
      "source": [
        "ü§ó Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.\n",
        "\n",
        "These models can be applied on:\n",
        "- üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.\n",
        "\n",
        "- üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.\n",
        "- üó£Ô∏è Audio, for tasks like speech recognition and audio classification.\n",
        "\n",
        "This is the pipeline method in transformers that we'll be using to analyze our sentiment data. Since we're not specifying a pretrained model, the pipeline has a default sentiment analysis model called [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c3e6e41",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "943a81a41a26464ebc0dc03b9dbb954e",
            "074f507569c9498583e2793c597ffc17",
            "56d277eab0c1468d8d9d8b74387306ee"
          ]
        },
        "id": "9c3e6e41",
        "outputId": "b6547a35-5287-49b1-d709-33f00be56548"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "943a81a41a26464ebc0dc03b9dbb954e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "074f507569c9498583e2793c597ffc17",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56d277eab0c1468d8d9d8b74387306ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e30b34b2",
      "metadata": {
        "id": "e30b34b2"
      },
      "source": [
        "In this example, we'll supply two polar sentiments and test out the model pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de41c494",
      "metadata": {
        "id": "de41c494",
        "outputId": "7e43b6f0-40f9-4f04-f2f1-371dd5fefab9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998694658279419},\n",
              " {'label': 'NEGATIVE', 'score': 0.994263231754303}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = [\"This is great!\", \"Oh no!\"]\n",
        "sentiment_pipeline(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39d04139",
      "metadata": {
        "id": "39d04139"
      },
      "source": [
        "The `label` in this case indicates the prediction for the sentiment type.\n",
        "\n",
        "The `score` indicates the confidence of the prediction (between 0 and 1).\n",
        "\n",
        "Since our sentiments were very polar, it was easier for the model to predict the sentiment type.\n",
        "\n",
        "Let's see what happens when we use a less clear example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c077f881",
      "metadata": {
        "id": "c077f881",
        "outputId": "151ecd78-e610-4b5c-b30b-c865bfc06a26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9955561757087708},\n",
              " {'label': 'NEGATIVE', 'score': 0.9860844016075134}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "challenging_sentiments = [\"I don't think freddriq should leave, he's been helpful.\",\n",
        "                          \"Is that the lake we went to last month?\"]\n",
        "sentiment_pipeline(challenging_sentiments)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c64b62d4",
      "metadata": {
        "id": "c64b62d4"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### Loading the Twitter Data\n",
        "\n",
        "Let's play with some twitter data. We'll be using a modified version of the [Elon Musk twitter dataset on Kaggle](https://www.kaggle.com/datasets/andradaolteanu/all-elon-musks-tweets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c1a44d0",
      "metadata": {
        "id": "4c1a44d0",
        "outputId": "3fa18099-c402-4a5e-b53d-26fee6cbaa35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['@vincent13031925 For now. Costs are decreasing rapidly.',\n",
            " 'Love this beautiful shot',\n",
            " '@agnostoxxx @CathieDWood @ARKInvest Trust the shrub',\n",
            " 'The art In Cyberpunk is incredible',\n",
            " '@itsALLrisky ü§£ü§£',\n",
            " '@seinfeldguru @WholeMarsBlog Nope haha',\n",
            " '@WholeMarsBlog If you don‚Äôt say anything &amp; engage Autopilot, it will '\n",
            " 'soon guess based on time of day, taking you home or to work or to what‚Äôs on '\n",
            " 'your calendar',\n",
            " '@DeltavPhotos @PortCanaveral That rocket is a hardcore veteran of many '\n",
            " 'missions',\n",
            " 'Blimps rock  https://t.co/e8cu5FkNOI',\n",
            " '@engineers_feed Due to lower gravity, you can travel from surface of Mars to '\n",
            " 'surface of Earth fairly easily with a single stage rocket. Earth to Mars is '\n",
            " 'vastly harder.',\n",
            " '@DrPhiltill Good thread',\n",
            " '@alexellisuk Pretty much',\n",
            " '@tesla_adri @WholeMarsBlog These things are best thought of as '\n",
            " 'probabilities. There are 5 forward-facing cameras. It is highly likely that '\n",
            " 'at least one of them will see multiple cars ahead.',\n",
            " '@WholeMarsBlog Sensors are a bitstream and cameras have several orders of '\n",
            " 'magnitude more bits/sec than radar (or lidar).   Radar must meaningfully '\n",
            " 'increase signal/noise of bitstream to be worth complexity of integrating '\n",
            " 'it.   As vision processing gets better, it just leaves radar far behind.',\n",
            " '@WholeMarsBlog When radar and vision disagree, which one do you believe? '\n",
            " 'Vision has much more precision, so better to double down on vision than do '\n",
            " 'sensor fusion.',\n",
            " '@WholeMarsBlog This is a major problem!',\n",
            " 'Just needs some legs',\n",
            " 'The Starship launch tower that catches the giant rocket booster is basically '\n",
            " 'Mechazilla',\n",
            " 'But wait how is the core of the earth lit by the sun? Stop asking '\n",
            " 'questions!!',\n",
            " 'Kong vs Godzilla has record for most meth ever consumed in a writer‚Äôs room',\n",
            " '@itsALLrisky üíØ',\n",
            " '‚Ä¶ going to moon very soon',\n",
            " '@Matsu_Kusarine @jagarikin Actually happened to me in Cyberpunk haha',\n",
            " '@TimBirks1 @Erdayastronaut @SpaceX Pretty much',\n",
            " '@memescryptor !',\n",
            " 'Where is Shrek 5!?  https://t.co/PqAZ5Mg8Es',\n",
            " '@AustinTeslaClub @OwenSparks_ @WholeMarsBlog Good point.   Next major '\n",
            " 'software rev will do much better with automating wipers, seat heating &amp; '\n",
            " 'defrost.   Probable seat settings just based on occupant mass distribution '\n",
            " 'should be possible.',\n",
            " '@Adamklotz_ @OwenSparks_ @WholeMarsBlog Yup',\n",
            " '@teslaownersSV @neuralink Turns out üêí love video games &amp; snacks just '\n",
            " 'like us!',\n",
            " 'It‚Äôs all about the cufflinks  https://t.co/elccqC0Zuf',\n",
            " '@chicago_glenn I feel like this sometimes',\n",
            " '@OwenSparks_ @WholeMarsBlog It will',\n",
            " '@OwenSparks_ @WholeMarsBlog Remove',\n",
            " '@w00ki33 @SpaceX @SuperclusterHQ Simulation is improving rendering '\n",
            " 'resolution  ‚Ä¶',\n",
            " '@cleantechnica Congrats to NIO. That is a tough milestone.',\n",
            " '@WholeMarsBlog Almost ready with FSD Beta V9.0. Step change improvement is '\n",
            " 'massive, especially for weird corner cases &amp; bad weather. Pure vision, '\n",
            " 'no radar.',\n",
            " 'Thanks to all that helped SpaceX!',\n",
            " 'Just read it. Book is accurate.',\n",
            " '@TeslaGong Yeah',\n",
            " '@mikevanbus @TrungTPhan @neuralink Pretty much',\n",
            " ' https://t.co/XeQursZpvq',\n",
            " 'Soon our monkey will be on twitch &amp; discord haha',\n",
            " '@thenewsoncnbc @contessabrewer Good piece!',\n",
            " '@Kyler_Knoll @neuralink Comes with wireless charging baseball cap',\n",
            " '@TarekWaked @TechCrunch @etherington Pretty much ü§£ü§£ Great episode!',\n",
            " 'A monkey is literally playing a video game telepathically using a brain '\n",
            " 'chip!!',\n",
            " '@lexfridman @neuralink Yes',\n",
            " 'The device is implanted flush with skull &amp; charges wirelessly, so you '\n",
            " 'look &amp; feel totally normal',\n",
            " '@IheartTesla Absolutely doable. Possibly as soon as Neuralink device version '\n",
            " '2, highly likely by version 3.',\n",
            " 'Later versions will be able to shunt signals from Neuralinks in brain to '\n",
            " 'Neuralinks in body motor/sensory neuron clusters, thus enabling, for '\n",
            " 'example, paraplegics to walk again',\n",
            " '@mindofkacper @neuralink Yes',\n",
            " 'First @Neuralink product will enable someone with paralysis to use a '\n",
            " 'smartphone with their mind faster than someone using thumbs',\n",
            " '@IheartTesla @neuralink Hopefully, later this year',\n",
            " '@tobyliiiiiiiiii Sure',\n",
            " 'Monkey plays Pong with his mind',\n",
            " '@dogeofficialceo @WatchersTank @SpaceX Looking at pups soon!',\n",
            " '@jordanxmajel @WatchersTank @SpaceX Shock absorption is built into tower '\n",
            " 'arms. Since tower is ground side, it can use a lot more mass to arrest '\n",
            " 'booster downward momentum.',\n",
            " '@jordanxmajel @WatchersTank @SpaceX Load points just below the grid fins',\n",
            " '@WatchersTank @SpaceX Just one skyscraper catching another nbd haha',\n",
            " 'Thanks Tesla suppliers for providing us with critical parts!',\n",
            " '@MarkJam93765764 @IvanEscobosa A tidal wave of vaccine is being produced!',\n",
            " '@jgrano305 Probably J&amp;J, but BioNtech &amp; Moderna are good too. Some '\n",
            " 'debate imo as to whether a second synthetic mRNA shot is really needed, but '\n",
            " 'the first is a no-brainer.',\n",
            " '@IvanEscobosa Latter',\n",
            " 'To be clear, I do support vaccines in general &amp; covid vaccines '\n",
            " 'specifically. The science is unequivocal.   In very rare cases, there is an '\n",
            " 'allergic reaction, but this is easily addressed with an EpiPen.',\n",
            " '@DavidWillisSLS @_Jevis_ @PPathole Needs legs for moon &amp; Mars',\n",
            " '@SciGuySpace Global payload to orbit is the key metric',\n",
            " '@Julius_Burton @Erdayastronaut @DJSnM @NASASpaceflight @ChrisG_NSF '\n",
            " '@thejackbeyer @FelixSchlang Nice',\n",
            " '@_Jevis_ @PPathole Ideal scenario imo is catching Starship in horizontal '\n",
            " '‚Äúglide‚Äù with no landing burn, although that is quite a challenge for the '\n",
            " 'tower! Next best is catching with tower, with emergency pad landing mode on '\n",
            " 'skirt (no legs).',\n",
            " '@PPathole Starship booster, largest flying object ever designed, will be '\n",
            " 'caught out of sky by launch tower. Big step forward, as reflight can be done '\n",
            " 'in under an hour.',\n",
            " '@WholeMarsBlog Well-written and fair, much like his articles on space',\n",
            " '@louisssdev @flcnhvy Coming soon. Crazy number of launches this year!',\n",
            " '@flcnhvy They will be recovered from the water &amp; reused',\n",
            " '‚ÄúTanks for the memery!‚Äù ‚Äì Panzer of the Lake',\n",
            " '@CathieDWood @wintonARK @ARKInvest What do you think of the unusually high '\n",
            " 'ratio of S&amp;P market cap to GDP?',\n",
            " '@ID_AA_Carmack Some kind of ELO level, updated once or twice a year based on '\n",
            " 'what someone actually got done, might be most effective. Important that it '\n",
            " 'go both up *and* down.',\n",
            " '@Thomas38697956 New &amp; improved version!',\n",
            " '@Teslarati @ResidentSponge Special mention of Tesla China',\n",
            " '@shbzz Obv',\n",
            " '@Teslarati @ResidentSponge Great work by Tesla team!',\n",
            " '@EvaFoxU Nice',\n",
            " 'The Earth is not flat, it‚Äôs a hollow globe &amp; Donkey King lives there!',\n",
            " '@EvaFoxU Those two really could have come in handy for the stuck ship!',\n",
            " '@EvaFoxU Last Kingdom vs Vikings',\n",
            " '@spacex360 Ascent phase, transition to horizontal &amp; control during free '\n",
            " 'fall were good.   A (relatively) small CH4 leak led to fire on engine 2 '\n",
            " '&amp; fried part of avionics, causing hard start attempting landing burn in '\n",
            " 'CH4 turbopump.   This is getting fixed 6 ways to Sunday.',\n",
            " 'Godzilla vs Kong is so amaze much wow! Most insane movie I‚Äôve ever seen! '\n",
            " 'Love letter to conspiracy theorists! And yet heartwarming in the end.',\n",
            " '@TerminalCount The Starships feast in Valhalla!',\n",
            " '@TerminalCount One of the greatest things I‚Äôve ever seen',\n",
            " '@floko12022021 @HamblinZeke @katlinegrey Ich habe ein Semester Deutsch an '\n",
            " 'der Universit√§t studiert usw',\n",
            " '@HamblinZeke @katlinegrey Haha Falcon? Nein!',\n",
            " '@tobyliiiiiiiiii @katlinegrey I recommend propulsive landing, as that is '\n",
            " 'extensible to planets, moons &amp; asteroids. Wings &amp; runways are '\n",
            " 'limited to Earth.',\n",
            " '@PPathole @katlinegrey For practical purposes, there is no limit. It will '\n",
            " 'just get increasingly difficult to service.',\n",
            " '@katlinegrey This a good path, but I recommend aiming for full reusability',\n",
            " 'Urgent need to build more housing in greater Austin area!',\n",
            " 'Austin++',\n",
            " 'No it doesn‚Äôt hurt at all ü©∏  https://t.co/NnL6o1si0V',\n",
            " '@allrocketsboi True',\n",
            " '@GerberKawasaki I fried a lot of neurons on that problem!',\n",
            " 'Me in my sick new car (left him the money)  https://t.co/EGaY1FVfHm',\n",
            " '@TrungTPhan Had no money to invest in Zip2, but my founder equity yielded '\n",
            " '~$15M after tax. Of that, I rolled ~$10M into PayPal, which yielded ~$180M, '\n",
            " 'then ‚Ä¶   Basic principle is that I would not ask investors to risk money on '\n",
            " 'my company if I would not also do so.',\n",
            " '@Gfilche Major new Supercharger station coming to Santa Monica soon! Hoping '\n",
            " 'to have 50‚Äôs diner &amp; 100 best movie clips playing too. Thanks Santa '\n",
            " 'Monica city!']\n"
          ]
        }
      ],
      "source": [
        "with open('../data/elonmusk_tweets.csv', newline='', encoding='utf8') as f:\n",
        "    tweets=[]\n",
        "    reader = csv.reader(f)\n",
        "    twitter_data = list(reader)\n",
        "    for tweet in twitter_data:\n",
        "        tweets.append(tweet[0])\n",
        "\n",
        "pprint(tweets[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e630a8f1",
      "metadata": {
        "id": "e630a8f1"
      },
      "source": [
        "First things first - let's look at the sentiment as determined by the [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) (default model) in the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42b10279",
      "metadata": {
        "id": "42b10279"
      },
      "outputs": [],
      "source": [
        "distil_sentiment = sentiment_pipeline(tweets[0:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ce3fefd",
      "metadata": {
        "id": "8ce3fefd"
      },
      "source": [
        "Let's check out the distribution of positive/negative Tweets and see the breakdown using Python's üêç standard library `collections.Counter`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "971a841d",
      "metadata": {
        "id": "971a841d",
        "outputId": "45c5eed0-6f9b-48da-8188-da9a2d8ed1b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49 (49.00%) of the tweets classified are positive.\n",
            "51 (51.00%) of the tweets classified are negative.\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "tweet_distro = Counter([x['label'] for x in distil_sentiment])\n",
        "pos_sent_count = tweet_distro['POSITIVE']\n",
        "neg_sent_count = tweet_distro['NEGATIVE']\n",
        "total_sent_count = sum(tweet_distro.values())\n",
        "\n",
        "print(f\"{pos_sent_count} ({pos_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are positive.\")\n",
        "print(f\"{neg_sent_count} ({neg_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are negative.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42155a0c",
      "metadata": {
        "id": "42155a0c"
      },
      "source": [
        "Let's do that process again, but use a model with an additional potential label \"NEUTRAL\" called [bertweet-sentiment-analysis](https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis)\n",
        "\n",
        "To start - we'll build a pipeline with the new model by using the ü§ó Hugging Face address: `finiteautomata/bertweet-base-sentiment-analysis`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd6e37f",
      "metadata": {
        "id": "3fd6e37f"
      },
      "outputs": [],
      "source": [
        "bertweet_pipeline = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7025127d",
      "metadata": {
        "id": "7025127d"
      },
      "source": [
        "Next, and the same as before, let's run the analysis on 100 of Elon's tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5daa650d",
      "metadata": {
        "id": "5daa650d"
      },
      "outputs": [],
      "source": [
        "bert_sentiment = bertweet_pipeline(tweets[0:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d8a316d",
      "metadata": {
        "id": "6d8a316d"
      },
      "source": [
        "And then, let's check out the breakdown of positive, negative, AND neutral sentiments!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6996cc58",
      "metadata": {
        "id": "6996cc58",
        "outputId": "49af4342-97e6-429d-d317-b48f300a0857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29 (29.00%) of the tweets classified are positive.\n",
            "64 (64.00%) of the tweets classified are neutral.\n",
            "7 (7.00%) of the tweets classified are negative.\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "tweet_distro = Counter([x['label'] for x in bert_sentiment])\n",
        "pos_sent_count = tweet_distro['POS']\n",
        "neu_sent_count = tweet_distro['NEU']\n",
        "neg_sent_count = tweet_distro['NEG']\n",
        "total_sent_count = sum(tweet_distro.values())\n",
        "\n",
        "print(f\"{pos_sent_count} ({pos_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are positive.\")\n",
        "print(f\"{neu_sent_count} ({neu_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are neutral.\")\n",
        "print(f\"{neg_sent_count} ({neg_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are negative.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8185798d",
      "metadata": {
        "id": "8185798d"
      },
      "source": [
        "**QUESTIONS**\n",
        "\n",
        "‚ùì What do you notice about the difference in the results? \n",
        "\n",
        "‚ùì Do the results for the `bertweet-base` model look better, or worse, than the results for the `distilbert-base` model? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùì What do you notice about the difference in the results?\n",
        "\n",
        "**Answer** :\n",
        "I notice that both the models had different results.\n",
        "Distilbert_base model classified 49 (49.00%) of the tweets as positive and 51 (51.00%) as negative.\n",
        "While, bertweet-base model classified 29 (29.00%) positive, \n",
        "64 (64.00%) neutral, and 7 (7.00%) as negative.\n",
        "\n",
        "Because bertweet-base model was able to classify some target values as  neutral as well, I am assuming Distilbert_base model classfied those 64 neutral datasets as positive and negative.  \n"
      ],
      "metadata": {
        "id": "LL54aJBH5eeg"
      },
      "id": "LL54aJBH5eeg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùì Do the results for the bertweet-base model look better, or worse, than the results for the distilbert-base model? Why?\n",
        "\n",
        "**Answer**: I would say distilbert-base model is giving us more details of our target value. We have a option to class neutral which bertweet-base model doesn't have. It's definetly good. But, I can't say which model is better based on how classes it can classify into.\n",
        "I would say we would require values like accuracy, precision, recall, F1 score to determine which model is better."
      ],
      "metadata": {
        "id": "fX4j-HYp6fyK"
      },
      "id": "fX4j-HYp6fyK"
    },
    {
      "cell_type": "markdown",
      "id": "6684f9ae",
      "metadata": {
        "id": "6684f9ae"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### Partner Exercise\n",
        "\n",
        "With your partner, try and determine what the following tweets might be classified as. Try to classify them into the same groups as both of the model pipelines we saw today - and try adding a few of your own sentences/Tweets! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcc55db9",
      "metadata": {
        "id": "dcc55db9"
      },
      "outputs": [],
      "source": [
        "example_difficult_tweets = [\n",
        "    \"Kong vs Godzilla has record for most meth ever consumed in a writer's room\",\n",
        "    \"@ashleevance Battery energy density is the key to electric aircraft. Autonomy for aircraft could have been done a long time ago. Modern airliners are very close to autonomous.\",\n",
        "    \"Tesla's action is not directly reflective of my opinion. Having some Bitcoin, which is simply a less dumb form of liquidity than cash, is adventurous enough for an S&P500 company.\",\n",
        "    \"Tesla is doing bad job.\",\n",
        "    \"I think, Elon will fail.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324e3837",
      "metadata": {
        "id": "324e3837"
      },
      "source": [
        "The `distilbert-base` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd3d5a9",
      "metadata": {
        "id": "3fd3d5a9",
        "outputId": "318d956d-da14-4360-8b4d-29dd37f5f44d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.5429078340530396}]\n",
            "Kong vs Godzilla has record for most meth ever consumed in a writer's room\n",
            "\n",
            "[{'label': 'NEGATIVE', 'score': 0.6348389387130737}]\n",
            "@ashleevance Battery energy density is the key to electric aircraft. Autonomy for aircraft could have been done a long time ago. Modern airliners are very close to autonomous.\n",
            "\n",
            "[{'label': 'POSITIVE', 'score': 0.941969096660614}]\n",
            "Tesla's action is not directly reflective of my opinion. Having some Bitcoin, which is simply a less dumb form of liquidity than cash, is adventurous enough for an S&P500 company.\n",
            "\n",
            "[{'label': 'NEGATIVE', 'score': 0.9996116757392883}]\n",
            "Tesla is doing bad job.\n",
            "\n",
            "[{'label': 'NEGATIVE', 'score': 0.9997225403785706}]\n",
            "I think, Elon will fail.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for tweet in example_difficult_tweets[0:1000]:\n",
        "    pprint(sentiment_pipeline(tweet))\n",
        "    print(tweet + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61230295",
      "metadata": {
        "id": "61230295"
      },
      "source": [
        "The `bertweet-base` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82f2d3e2",
      "metadata": {
        "id": "82f2d3e2",
        "outputId": "cdb78a4a-be21-47ad-93e8-668d1ad26132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'NEG', 'score': 0.7213016152381897}]\n",
            "Kong vs Godzilla has record for most meth ever consumed in a writer's room\n",
            "\n",
            "[{'label': 'NEU', 'score': 0.802384078502655}]\n",
            "@ashleevance Battery energy density is the key to electric aircraft. Autonomy for aircraft could have been done a long time ago. Modern airliners are very close to autonomous.\n",
            "\n",
            "[{'label': 'NEU', 'score': 0.8843538165092468}]\n",
            "Tesla's action is not directly reflective of my opinion. Having some Bitcoin, which is simply a less dumb form of liquidity than cash, is adventurous enough for an S&P500 company.\n",
            "\n",
            "[{'label': 'NEG', 'score': 0.9839224815368652}]\n",
            "Tesla is doing bad job.\n",
            "\n",
            "[{'label': 'NEG', 'score': 0.9519268870353699}]\n",
            "I think, Elon will fail.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for tweet in example_difficult_tweets[0:1000]:\n",
        "    pprint(bertweet_pipeline(tweet))\n",
        "    print(tweet + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f2c1c5",
      "metadata": {
        "id": "97f2c1c5"
      },
      "source": [
        "**QUESTIONS**\n",
        "\n",
        "‚ùì How did you do? Did you find any surprising results? \n",
        "\n",
        "‚ùì Are there any instances where the two models gave different predictions for the same tweet?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùì How did you do? Did you find any surprising results?\n",
        "\n",
        "**Answer** : I fed the dataset into the model and printed the classes based on the model's algorithm.\n",
        "Yes, I found it really surprising that two models gave different prediction for the \"Kong vs Godzilla has record for most meth ever consumed in a writer's room\"."
      ],
      "metadata": {
        "id": "jFj_4XFE_eWD"
      },
      "id": "jFj_4XFE_eWD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùì Are there any instances where the two models gave different predictions for the same tweet?\n",
        "\n",
        "**Answer** : Yes, Two models gave different predicted class for this target value,\" Kong vs Godzilla has record for most meth ever consumed in a writer's room\" .\n",
        "Distil_bert-base model labelled it positive with score of 0.54 while bertweet-base model labelled it negative with score of 0.71.\n",
        "\n"
      ],
      "metadata": {
        "id": "ai1MLPvRAIUe"
      },
      "id": "ai1MLPvRAIUe"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "635e31ff34c0350df6e9d804eda70786d94f48b17fcc73c378df4ea6ec0d01fd"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}